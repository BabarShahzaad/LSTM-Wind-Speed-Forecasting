{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from io import BytesIO\n",
    "from ish_parser import ish_parser\n",
    "\n",
    "def read_observations(years, usaf='081810', wban='99999'):\n",
    "    parser = ish_parser()\n",
    "    \n",
    "    for year in years:\n",
    "        path = \"../data/observations/{usaf}-{wban}-{year}.gz\".format(year=year, usaf=usaf, wban=wban)\n",
    "        with gzip.open(path) as gz:\n",
    "            parser.loads(bytes.decode(gz.read()))\n",
    "            \n",
    "    reports = parser.get_reports()\n",
    "    \n",
    "    station_latitudes = [41.283, 41.293] \n",
    "    observations = pd.DataFrame.from_records(((r.datetime, \n",
    "                                               r.air_temperature.get_numeric(),\n",
    "                                               (r.precipitation[0]['depth'].get_numeric() if r.precipitation else 0),\n",
    "                                               r.humidity.get_numeric(),\n",
    "                                               r.sea_level_pressure.get_numeric(),\n",
    "                                               r.wind_speed.get_numeric(),\n",
    "                                               r.wind_direction.get_numeric()) \n",
    "                                              for r in reports if r.latitude in station_latitudes and r.datetime.minute == 0),\n",
    "                             columns=['timestamp', 'AT', 'precipitation', 'humidity', 'pressure', 'wind_speed', 'wind_direction'], \n",
    "                             index='timestamp')\n",
    "    \n",
    "    return observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nems4_lookahead = 12\n",
    "\n",
    "def read_nems4(years, prediction_hours=12):\n",
    "    predictions=pd.DataFrame()\n",
    "    for year in years:\n",
    "        with open('../data/NEMS4/{}.json'.format(year)) as json_data:\n",
    "            d = json.load(json_data)\n",
    "            if not predictions.empty:\n",
    "                predictions = predictions.append(pd.DataFrame(d['history_1h']))\n",
    "            else:\n",
    "                predictions = pd.DataFrame(d['history_1h'])\n",
    "\n",
    "    predictions = predictions.set_index('time')\n",
    "    predictions.index.name = 'timestamp'\n",
    "    \n",
    "    # shift dataset back 12 hours as its a the value is the prediction for the given timestmap 12 hours previously\n",
    "    predictions.index = pd.to_datetime(predictions.index) - pd.Timedelta(hours=nems4_lookahead)\n",
    "    predictions.index.tz = 'UTC'\n",
    "\n",
    "    predictions = predictions[['temperature', 'precipitation', \n",
    "                   'relativehumidity', 'sealevelpressure', \n",
    "                   'windspeed', 'winddirection']]\n",
    "    \n",
    "    predictions = predictions.rename(columns={\n",
    "        'windspeed': 'nems4_wind_speed',\n",
    "        'winddirection': 'nems4_wind_direction', \n",
    "        'temperature': 'nems4_AT',\n",
    "        'precipitation': 'nems4_precipitation',\n",
    "        'relativehumidity': 'nems4_humidity',\n",
    "        'sealevelpressure': 'nems4_pressure'})\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>nems4_AT</th>\n",
       "      <th>nems4_precipitation</th>\n",
       "      <th>nems4_humidity</th>\n",
       "      <th>nems4_pressure</th>\n",
       "      <th>nems4_wind_speed</th>\n",
       "      <th>nems4_wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76096.000000</td>\n",
       "      <td>76005.000000</td>\n",
       "      <td>76073.000000</td>\n",
       "      <td>59702.000000</td>\n",
       "      <td>76145.000000</td>\n",
       "      <td>74446.000000</td>\n",
       "      <td>76161.000000</td>\n",
       "      <td>76161.000000</td>\n",
       "      <td>76161.000000</td>\n",
       "      <td>76161.000000</td>\n",
       "      <td>76161.000000</td>\n",
       "      <td>76161.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.882632</td>\n",
       "      <td>0.076991</td>\n",
       "      <td>67.859135</td>\n",
       "      <td>1016.604899</td>\n",
       "      <td>4.111837</td>\n",
       "      <td>235.901056</td>\n",
       "      <td>16.380258</td>\n",
       "      <td>0.036410</td>\n",
       "      <td>70.884521</td>\n",
       "      <td>1016.181576</td>\n",
       "      <td>3.506167</td>\n",
       "      <td>210.305419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.782857</td>\n",
       "      <td>1.069337</td>\n",
       "      <td>14.420932</td>\n",
       "      <td>6.886706</td>\n",
       "      <td>2.112691</td>\n",
       "      <td>107.677121</td>\n",
       "      <td>6.757949</td>\n",
       "      <td>0.279013</td>\n",
       "      <td>16.583534</td>\n",
       "      <td>7.148011</td>\n",
       "      <td>1.983231</td>\n",
       "      <td>107.191350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>980.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-5.840000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>982.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1012.900000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>11.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1016.900000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>16.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "      <td>3.140000</td>\n",
       "      <td>212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1020.600000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>21.540000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>4.620000</td>\n",
       "      <td>318.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35.300000</td>\n",
       "      <td>75.900000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1041.600000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>39.210000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1044.000000</td>\n",
       "      <td>22.320000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT  precipitation      humidity      pressure    wind_speed  \\\n",
       "count  76096.000000   76005.000000  76073.000000  59702.000000  76145.000000   \n",
       "mean      16.882632       0.076991     67.859135   1016.604899      4.111837   \n",
       "std        6.782857       1.069337     14.420932      6.886706      2.112691   \n",
       "min       -3.500000       0.000000      8.000000    980.200000      0.000000   \n",
       "25%       11.700000       0.000000     59.000000   1012.900000      2.600000   \n",
       "50%       16.800000       0.000000     69.000000   1016.900000      4.100000   \n",
       "75%       22.500000       0.000000     78.000000   1020.600000      5.100000   \n",
       "max       35.300000      75.900000    100.000000   1041.600000     27.800000   \n",
       "\n",
       "       wind_direction      nems4_AT  nems4_precipitation  nems4_humidity  \\\n",
       "count    74446.000000  76161.000000         76161.000000    76161.000000   \n",
       "mean       235.901056     16.380258             0.036410       70.884521   \n",
       "std        107.677121      6.757949             0.279013       16.583534   \n",
       "min         10.000000     -5.840000             0.000000        1.000000   \n",
       "25%        160.000000     11.390000             0.000000       59.000000   \n",
       "50%        240.000000     16.570000             0.000000       72.000000   \n",
       "75%        340.000000     21.540000             0.000000       85.000000   \n",
       "max        360.000000     39.210000            16.000000      100.000000   \n",
       "\n",
       "       nems4_pressure  nems4_wind_speed  nems4_wind_direction  \n",
       "count    76161.000000      76161.000000          76161.000000  \n",
       "mean      1016.181576          3.506167            210.305419  \n",
       "std          7.148011          1.983231            107.191350  \n",
       "min        982.000000          0.000000              0.000000  \n",
       "25%       1012.000000          2.050000            120.000000  \n",
       "50%       1017.000000          3.140000            212.000000  \n",
       "75%       1020.000000          4.620000            318.000000  \n",
       "max       1044.000000         22.320000            360.000000  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = range(2007, 2016)\n",
    "dataset = pd.merge(read_observations(years), read_nems4(years), left_index=True, right_index=True, how='inner')\n",
    "# dataset = read_observations(years)\n",
    "\n",
    "original = dataset.copy(deep=True)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "np.random.seed(1234)\n",
    "\n",
    "def drop_duplicates(df):\n",
    "    print(\"Number of duplicates: {}\".format(len(df.index.get_duplicates())))\n",
    "    return df[~df.index.duplicated(keep='first')]\n",
    "    \n",
    "def impute_missing(df):\n",
    "    # todo test with moving average / mean or something smarter than forward fill\n",
    "    print(\"Number of rows with nan: {}\".format(np.count_nonzero(df.isnull())))\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    return df\n",
    "    \n",
    "def first_order_difference(data, columns):\n",
    "    for column in columns:\n",
    "        data[column+'_d'] = data[column].diff(periods=1)\n",
    "    \n",
    "    return data.dropna()\n",
    "\n",
    "# def derive_prediction_columns(data, column, column2, horizons):\n",
    "#     for look_ahead in horizons:\n",
    "#         data['prediction_' + str(look_ahead)] = data[column].diff(periods=look_ahead).shift(-look_ahead)\n",
    "        \n",
    "#     for look_ahead in horizons:\n",
    "#         data['prediction_direction_' + str(look_ahead)] = data[column2].diff(periods=look_ahead).shift(-look_ahead)\n",
    "\n",
    "def derive_prediction_columns(data, column, horizons):\n",
    "    for look_ahead in horizons:\n",
    "        data['prediction_' + str(look_ahead)] = data[column].diff(periods=look_ahead).shift(-look_ahead)\n",
    "    \n",
    "    return data.dropna()\n",
    "\n",
    "def scale_features(scaler, features):\n",
    "    scaler.fit(features)\n",
    "    \n",
    "    scaled = scaler.transform(features)\n",
    "    scaled = pd.DataFrame(scaled, columns=features.columns)\n",
    "    \n",
    "    return scaled\n",
    "\n",
    "def inverse_prediction_scale(scaler, predictions, original_columns, column):\n",
    "    loc = original_columns.get_loc(column)\n",
    "    \n",
    "    inverted = np.zeros((len(predictions), len(original_columns)))\n",
    "    inverted[:,loc] = np.reshape(predictions, (predictions.shape[0],))\n",
    "    \n",
    "    inverted = scaler.inverse_transform(inverted)[:,loc] # Scale back the data to the original representation\n",
    "    \n",
    "    return inverted\n",
    "\n",
    "# def invert_all_prediction_scaled(scaler, predictions, original_columns, horizons):\n",
    "#     inverted = np.zeros(predictions.shape)\n",
    "#     inverted2 = np.zeros(predictions.shape)\n",
    "    \n",
    "#     for col_idx, horizon in enumerate(horizons):\n",
    "#         inverted[:,col_idx] = inverse_prediction_scale(\n",
    "#             scaler, predictions[:,col_idx], \n",
    "#             original_columns,\n",
    "#             \"prediction_\" + str(horizon))\n",
    "\n",
    "#     for col_idx, horizon in enumerate(horizons):\n",
    "#         inverted2[:,col_idx] = inverse_prediction_scale(\n",
    "#             scaler, predictions[:,col_idx], \n",
    "#             original_columns,\n",
    "#             \"prediction_direction_\" + str(horizon))\n",
    "    \n",
    "#     return inverted, inverted2\n",
    "\n",
    "def invert_all_prediction_scaled(scaler, predictions, original_columns, horizons):\n",
    "    inverted = np.zeros(predictions.shape)\n",
    "    \n",
    "    for col_idx, horizon in enumerate(horizons):\n",
    "        inverted[:,col_idx] = inverse_prediction_scale(\n",
    "            scaler, predictions[:,col_idx], \n",
    "            original_columns,\n",
    "            \"prediction_\" + str(horizon))\n",
    "    \n",
    "    return inverted\n",
    "\n",
    "def inverse_prediction_difference(predictions, original):\n",
    "    return predictions + original\n",
    "\n",
    "def invert_all_prediction_differences(predictions, original):\n",
    "    inverted = predictions\n",
    "    \n",
    "    for col_idx, horizon in enumerate(horizons):\n",
    "        inverted[:, col_idx] = inverse_prediction_difference(predictions[:,col_idx], original)\n",
    "        \n",
    "    return inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 189\n",
      "Number of rows with nan: 18443\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>nems4_AT</th>\n",
       "      <th>nems4_precipitation</th>\n",
       "      <th>nems4_humidity</th>\n",
       "      <th>nems4_pressure</th>\n",
       "      <th>nems4_wind_speed</th>\n",
       "      <th>nems4_wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>75972.000000</td>\n",
       "      <td>75972.000000</td>\n",
       "      <td>75972.000000</td>\n",
       "      <td>75972.000000</td>\n",
       "      <td>75972.000000</td>\n",
       "      <td>75972.000000</td>\n",
       "      <td>75972.000000</td>\n",
       "      <td>75972.000000</td>\n",
       "      <td>75972.000000</td>\n",
       "      <td>75972.000000</td>\n",
       "      <td>75972.000000</td>\n",
       "      <td>75972.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.904299</td>\n",
       "      <td>0.076945</td>\n",
       "      <td>67.853630</td>\n",
       "      <td>1016.279315</td>\n",
       "      <td>4.111719</td>\n",
       "      <td>235.939425</td>\n",
       "      <td>16.397896</td>\n",
       "      <td>0.036491</td>\n",
       "      <td>70.878179</td>\n",
       "      <td>1016.174643</td>\n",
       "      <td>3.505294</td>\n",
       "      <td>210.255357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.776936</td>\n",
       "      <td>1.069462</td>\n",
       "      <td>14.426722</td>\n",
       "      <td>7.002261</td>\n",
       "      <td>2.113328</td>\n",
       "      <td>107.526579</td>\n",
       "      <td>6.754892</td>\n",
       "      <td>0.279351</td>\n",
       "      <td>16.587193</td>\n",
       "      <td>7.140868</td>\n",
       "      <td>1.980608</td>\n",
       "      <td>107.176558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>980.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-5.840000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>982.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1012.500000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>11.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1016.700000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>1017.000000</td>\n",
       "      <td>3.140000</td>\n",
       "      <td>212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1020.400000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>21.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>4.620000</td>\n",
       "      <td>318.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35.300000</td>\n",
       "      <td>75.900000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1041.600000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>39.210000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1044.000000</td>\n",
       "      <td>22.320000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT  precipitation      humidity      pressure    wind_speed  \\\n",
       "count  75972.000000   75972.000000  75972.000000  75972.000000  75972.000000   \n",
       "mean      16.904299       0.076945     67.853630   1016.279315      4.111719   \n",
       "std        6.776936       1.069462     14.426722      7.002261      2.113328   \n",
       "min       -3.500000       0.000000      8.000000    980.200000      0.000000   \n",
       "25%       11.800000       0.000000     59.000000   1012.500000      2.600000   \n",
       "50%       16.900000       0.000000     69.000000   1016.700000      4.100000   \n",
       "75%       22.500000       0.000000     78.000000   1020.400000      5.100000   \n",
       "max       35.300000      75.900000    100.000000   1041.600000     27.800000   \n",
       "\n",
       "       wind_direction      nems4_AT  nems4_precipitation  nems4_humidity  \\\n",
       "count    75972.000000  75972.000000         75972.000000    75972.000000   \n",
       "mean       235.939425     16.397896             0.036491       70.878179   \n",
       "std        107.526579      6.754892             0.279351       16.587193   \n",
       "min         10.000000     -5.840000             0.000000        1.000000   \n",
       "25%        160.000000     11.420000             0.000000       59.000000   \n",
       "50%        240.000000     16.600000             0.000000       72.000000   \n",
       "75%        340.000000     21.550000             0.000000       85.000000   \n",
       "max        360.000000     39.210000            16.000000      100.000000   \n",
       "\n",
       "       nems4_pressure  nems4_wind_speed  nems4_wind_direction  \n",
       "count    75972.000000      75972.000000          75972.000000  \n",
       "mean      1016.174643          3.505294            210.255357  \n",
       "std          7.140868          1.980608            107.176558  \n",
       "min        982.000000          0.000000              0.000000  \n",
       "25%       1012.000000          2.050000            120.000000  \n",
       "50%       1017.000000          3.140000            212.000000  \n",
       "75%       1020.000000          4.620000            318.000000  \n",
       "max       1044.000000         22.320000            360.000000  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = drop_duplicates(dataset)\n",
    "dataset = impute_missing(dataset)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select features we're going to use\n",
    "features = dataset[['wind_speed', \n",
    "                    'nems4_wind_speed',\n",
    "#                     'wind_direction',\n",
    "#                     'nems4_wind_direction', \n",
    "                    'AT', \n",
    "                    'nems4_AT', \n",
    "                    'humidity', \n",
    "                    'nems4_humidity',\n",
    "                    'pressure',\n",
    "                    'nems4_pressure']]\n",
    "\n",
    "# features = dataset[['wind_speed', \n",
    "# #                     'wind_direction', \n",
    "#                     'AT', \n",
    "#                     'humidity', \n",
    "#                     'pressure']]\n",
    "\n",
    "# the time horizons we're going to predict (in hours)\n",
    "horizons = [1, 2, 4]\n",
    "\n",
    "features = first_order_difference(features, features.columns)\n",
    "features = derive_prediction_columns(features, 'wind_speed', horizons)\n",
    "# features = derive_prediction_columns(features, 'wind_speed', 'wind_direction', horizons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>nems4_wind_speed</th>\n",
       "      <th>AT</th>\n",
       "      <th>nems4_AT</th>\n",
       "      <th>humidity</th>\n",
       "      <th>nems4_humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>nems4_pressure</th>\n",
       "      <th>wind_speed_d</th>\n",
       "      <th>nems4_wind_speed_d</th>\n",
       "      <th>AT_d</th>\n",
       "      <th>nems4_AT_d</th>\n",
       "      <th>humidity_d</th>\n",
       "      <th>nems4_humidity_d</th>\n",
       "      <th>pressure_d</th>\n",
       "      <th>nems4_pressure_d</th>\n",
       "      <th>prediction_1</th>\n",
       "      <th>prediction_2</th>\n",
       "      <th>prediction_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "      <td>7.596700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-8.557838e-16</td>\n",
       "      <td>2.031495e-16</td>\n",
       "      <td>-4.652686e-17</td>\n",
       "      <td>-1.407402e-16</td>\n",
       "      <td>-3.981002e-18</td>\n",
       "      <td>-3.735390e-16</td>\n",
       "      <td>1.954055e-14</td>\n",
       "      <td>-3.668563e-15</td>\n",
       "      <td>6.373402e-18</td>\n",
       "      <td>1.331531e-17</td>\n",
       "      <td>-3.101645e-17</td>\n",
       "      <td>9.641214e-18</td>\n",
       "      <td>-9.549489e-19</td>\n",
       "      <td>-3.948850e-18</td>\n",
       "      <td>-4.204049e-16</td>\n",
       "      <td>2.120103e-16</td>\n",
       "      <td>-3.989482e-17</td>\n",
       "      <td>5.608331e-18</td>\n",
       "      <td>-2.210450e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.945611e+00</td>\n",
       "      <td>-1.769794e+00</td>\n",
       "      <td>-3.010936e+00</td>\n",
       "      <td>-3.292083e+00</td>\n",
       "      <td>-4.148757e+00</td>\n",
       "      <td>-4.212724e+00</td>\n",
       "      <td>-5.152826e+00</td>\n",
       "      <td>-4.785885e+00</td>\n",
       "      <td>-1.445179e+01</td>\n",
       "      <td>-1.485796e+01</td>\n",
       "      <td>-9.609931e+00</td>\n",
       "      <td>-8.614736e+00</td>\n",
       "      <td>-7.817818e+00</td>\n",
       "      <td>-1.220231e+01</td>\n",
       "      <td>-3.845770e+01</td>\n",
       "      <td>-1.784291e+01</td>\n",
       "      <td>-1.445179e+01</td>\n",
       "      <td>-1.232098e+01</td>\n",
       "      <td>-9.370831e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.153279e-01</td>\n",
       "      <td>-7.347696e-01</td>\n",
       "      <td>-7.532574e-01</td>\n",
       "      <td>-7.376861e-01</td>\n",
       "      <td>-6.136434e-01</td>\n",
       "      <td>-7.160871e-01</td>\n",
       "      <td>-5.396601e-01</td>\n",
       "      <td>-5.845459e-01</td>\n",
       "      <td>-7.190357e-01</td>\n",
       "      <td>-5.231252e-01</td>\n",
       "      <td>-5.709047e-01</td>\n",
       "      <td>-5.341246e-01</td>\n",
       "      <td>-5.211921e-01</td>\n",
       "      <td>-5.229409e-01</td>\n",
       "      <td>-3.510126e-01</td>\n",
       "      <td>1.264732e-04</td>\n",
       "      <td>-7.190316e-01</td>\n",
       "      <td>-5.575243e-01</td>\n",
       "      <td>-6.507894e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-5.549267e-03</td>\n",
       "      <td>-1.844395e-01</td>\n",
       "      <td>-6.977215e-04</td>\n",
       "      <td>2.989137e-02</td>\n",
       "      <td>7.951622e-02</td>\n",
       "      <td>6.764186e-02</td>\n",
       "      <td>6.019424e-02</td>\n",
       "      <td>1.156774e-01</td>\n",
       "      <td>-4.353685e-05</td>\n",
       "      <td>-4.688765e-05</td>\n",
       "      <td>-9.516643e-02</td>\n",
       "      <td>-1.550767e-01</td>\n",
       "      <td>-4.573807e-06</td>\n",
       "      <td>1.606267e-05</td>\n",
       "      <td>2.011109e-04</td>\n",
       "      <td>1.264732e-04</td>\n",
       "      <td>-3.880462e-05</td>\n",
       "      <td>-1.467768e-05</td>\n",
       "      <td>-3.997565e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.676365e-01</td>\n",
       "      <td>5.627977e-01</td>\n",
       "      <td>8.256423e-01</td>\n",
       "      <td>7.626799e-01</td>\n",
       "      <td>7.033598e-01</td>\n",
       "      <td>8.513708e-01</td>\n",
       "      <td>5.886374e-01</td>\n",
       "      <td>5.358113e-01</td>\n",
       "      <td>4.313518e-01</td>\n",
       "      <td>4.607602e-01</td>\n",
       "      <td>3.805718e-01</td>\n",
       "      <td>3.704214e-01</td>\n",
       "      <td>5.211830e-01</td>\n",
       "      <td>5.229730e-01</td>\n",
       "      <td>3.514148e-01</td>\n",
       "      <td>1.264732e-04</td>\n",
       "      <td>4.313569e-01</td>\n",
       "      <td>5.574949e-01</td>\n",
       "      <td>6.507094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.120895e+01</td>\n",
       "      <td>9.499351e+00</td>\n",
       "      <td>2.714420e+00</td>\n",
       "      <td>3.377033e+00</td>\n",
       "      <td>2.228311e+00</td>\n",
       "      <td>1.755673e+00</td>\n",
       "      <td>3.616474e+00</td>\n",
       "      <td>3.896883e+00</td>\n",
       "      <td>1.926895e+01</td>\n",
       "      <td>1.295237e+01</td>\n",
       "      <td>9.705041e+00</td>\n",
       "      <td>8.554409e+00</td>\n",
       "      <td>8.165267e+00</td>\n",
       "      <td>1.133075e+01</td>\n",
       "      <td>2.616562e+01</td>\n",
       "      <td>1.784316e+01</td>\n",
       "      <td>1.926897e+01</td>\n",
       "      <td>1.321296e+01</td>\n",
       "      <td>1.093255e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         wind_speed  nems4_wind_speed            AT      nems4_AT  \\\n",
       "count  7.596700e+04      7.596700e+04  7.596700e+04  7.596700e+04   \n",
       "mean  -8.557838e-16      2.031495e-16 -4.652686e-17 -1.407402e-16   \n",
       "std    1.000007e+00      1.000007e+00  1.000007e+00  1.000007e+00   \n",
       "min   -1.945611e+00     -1.769794e+00 -3.010936e+00 -3.292083e+00   \n",
       "25%   -7.153279e-01     -7.347696e-01 -7.532574e-01 -7.376861e-01   \n",
       "50%   -5.549267e-03     -1.844395e-01 -6.977215e-04  2.989137e-02   \n",
       "75%    4.676365e-01      5.627977e-01  8.256423e-01  7.626799e-01   \n",
       "max    1.120895e+01      9.499351e+00  2.714420e+00  3.377033e+00   \n",
       "\n",
       "           humidity  nems4_humidity      pressure  nems4_pressure  \\\n",
       "count  7.596700e+04    7.596700e+04  7.596700e+04    7.596700e+04   \n",
       "mean  -3.981002e-18   -3.735390e-16  1.954055e-14   -3.668563e-15   \n",
       "std    1.000007e+00    1.000007e+00  1.000007e+00    1.000007e+00   \n",
       "min   -4.148757e+00   -4.212724e+00 -5.152826e+00   -4.785885e+00   \n",
       "25%   -6.136434e-01   -7.160871e-01 -5.396601e-01   -5.845459e-01   \n",
       "50%    7.951622e-02    6.764186e-02  6.019424e-02    1.156774e-01   \n",
       "75%    7.033598e-01    8.513708e-01  5.886374e-01    5.358113e-01   \n",
       "max    2.228311e+00    1.755673e+00  3.616474e+00    3.896883e+00   \n",
       "\n",
       "       wind_speed_d  nems4_wind_speed_d          AT_d    nems4_AT_d  \\\n",
       "count  7.596700e+04        7.596700e+04  7.596700e+04  7.596700e+04   \n",
       "mean   6.373402e-18        1.331531e-17 -3.101645e-17  9.641214e-18   \n",
       "std    1.000007e+00        1.000007e+00  1.000007e+00  1.000007e+00   \n",
       "min   -1.445179e+01       -1.485796e+01 -9.609931e+00 -8.614736e+00   \n",
       "25%   -7.190357e-01       -5.231252e-01 -5.709047e-01 -5.341246e-01   \n",
       "50%   -4.353685e-05       -4.688765e-05 -9.516643e-02 -1.550767e-01   \n",
       "75%    4.313518e-01        4.607602e-01  3.805718e-01  3.704214e-01   \n",
       "max    1.926895e+01        1.295237e+01  9.705041e+00  8.554409e+00   \n",
       "\n",
       "         humidity_d  nems4_humidity_d    pressure_d  nems4_pressure_d  \\\n",
       "count  7.596700e+04      7.596700e+04  7.596700e+04      7.596700e+04   \n",
       "mean  -9.549489e-19     -3.948850e-18 -4.204049e-16      2.120103e-16   \n",
       "std    1.000007e+00      1.000007e+00  1.000007e+00      1.000007e+00   \n",
       "min   -7.817818e+00     -1.220231e+01 -3.845770e+01     -1.784291e+01   \n",
       "25%   -5.211921e-01     -5.229409e-01 -3.510126e-01      1.264732e-04   \n",
       "50%   -4.573807e-06      1.606267e-05  2.011109e-04      1.264732e-04   \n",
       "75%    5.211830e-01      5.229730e-01  3.514148e-01      1.264732e-04   \n",
       "max    8.165267e+00      1.133075e+01  2.616562e+01      1.784316e+01   \n",
       "\n",
       "       prediction_1  prediction_2  prediction_4  \n",
       "count  7.596700e+04  7.596700e+04  7.596700e+04  \n",
       "mean  -3.989482e-17  5.608331e-18 -2.210450e-18  \n",
       "std    1.000007e+00  1.000007e+00  1.000007e+00  \n",
       "min   -1.445179e+01 -1.232098e+01 -9.370831e+00  \n",
       "25%   -7.190316e-01 -5.575243e-01 -6.507894e-01  \n",
       "50%   -3.880462e-05 -1.467768e-05 -3.997565e-05  \n",
       "75%    4.313569e-01  5.574949e-01  6.507094e-01  \n",
       "max    1.926897e+01  1.321296e+01  1.093255e+01  "
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "scaled = scale_features(scaler, features)\n",
    "\n",
    "scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_test_train(data, features, predictions, sequence_length, split_percent=0.9):\n",
    "    \n",
    "    num_features = len(features)\n",
    "    num_predictions = len(predictions)\n",
    "    \n",
    "    # make sure prediction cols are at end\n",
    "    columns = features + predictions\n",
    "    \n",
    "    data = data[columns].values\n",
    "    \n",
    "    print(\"Using {} features to predict {} horizons\".format(num_features, num_predictions))\n",
    "    \n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length+1):\n",
    "        result.append(data[index:index + sequence_length])\n",
    "\n",
    "    result = np.array(result)\n",
    "    # shape (n_samples, sequence_length, num_features + num_predictions)\n",
    "    print(\"Shape of data: {}\".format(np.shape(result)))\n",
    "    \n",
    "    row = round(split_percent * result.shape[0])\n",
    "    train = result[:row, :]\n",
    "    print(\"Shape of train: {}\".format(np.shape(train)))\n",
    "    \n",
    "    X_train = train[:, :, :-num_predictions]\n",
    "    y_train = train[:, -1, -num_predictions:]\n",
    "    X_test = result[row:, :, :-num_predictions]\n",
    "    y_test = result[row:, -1, -num_predictions:]\n",
    "    \n",
    "    print(\"Shape of X train: {}\".format(np.shape(X_train)))\n",
    "    print(\"Shape of y train: {}\".format(np.shape(y_train)))\n",
    "    print(\"Shape of X test: {}\".format(np.shape(X_test)))\n",
    "    \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], num_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], num_features))\n",
    "    \n",
    "    y_train = np.reshape(y_train, (y_train.shape[0], num_predictions))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0], num_predictions))\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 features to predict 3 horizons\n",
      "Shape of data: (75896, 72, 11)\n",
      "Shape of train: (60717, 72, 11)\n",
      "Shape of X train: (60717, 72, 8)\n",
      "Shape of y train: (60717, 3)\n",
      "Shape of X test: (15179, 72, 8)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 72\n",
    "\n",
    "prediction_cols = ['prediction_' + str(h) for h in horizons]\n",
    "# prediction_cols_2 = ['prediction_direction_' + str(h) for h in horizons]\n",
    "# prediction_cols = prediction_cols + prediction_cols_2\n",
    "\n",
    "feature_cols = ['wind_speed', 'nems4_wind_speed', \n",
    "#                 'wind_direction_d', 'nems4_wind_direction_d',\n",
    "                'AT', 'nems4_AT', \n",
    "                'humidity', 'nems4_humidity', \n",
    "                'pressure', 'nems4_pressure']\n",
    "\n",
    "# feature_cols = ['wind_speed_d', 'nems4_wind_speed_d', \n",
    "# #                 'wind_direction_d', 'nems4_wind_direction_d',\n",
    "#                 'AT_d', 'nems4_AT_d', \n",
    "#                 'humidity_d', 'nems4_humidity_d', \n",
    "#                 'pressure_d', 'nems4_pressure_d']\n",
    "\n",
    "# feature_cols = ['wind_speed_d', \n",
    "# #                 'wind_direction_d', \n",
    "#                 'AT_d', \n",
    "#                 'humidity_d', \n",
    "#                 'pressure_d']\n",
    "\n",
    "X_train, y_train, X_test, y_test, row_split = prepare_test_train(\n",
    "    scaled,\n",
    "    feature_cols,\n",
    "    prediction_cols,\n",
    "    sequence_length,\n",
    "    split_percent = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "#(-1 is because we only take the last y row in each sequence)\n",
    "sequence_offset = sequence_length - 1\n",
    "\n",
    "# validate train\n",
    "inverse_scale = invert_all_prediction_scaled(scaler, y_train, scaled.columns, horizons)\n",
    "\n",
    "assert(mean_squared_error(\n",
    "    features[prediction_cols][sequence_offset:row_split+sequence_offset], \n",
    "    inverse_scale) < 1e-10)\n",
    "\n",
    "\n",
    "undiff_prediction = invert_all_prediction_differences(\n",
    "    inverse_scale, \n",
    "    features['wind_speed'][sequence_offset:row_split+sequence_offset])\n",
    "\n",
    "for i, horizon in enumerate(horizons):\n",
    "    assert(mean_squared_error(\n",
    "        features['wind_speed'][sequence_offset+horizon:row_split+sequence_offset+horizon], \n",
    "        undiff_prediction[:,i]) < 1e-10)\n",
    "\n",
    "    \n",
    "# validate test\n",
    "inverse_scale = invert_all_prediction_scaled(scaler, y_test, scaled.columns, horizons)\n",
    "\n",
    "assert(mean_squared_error(\n",
    "    features[prediction_cols][sequence_offset+row_split:], \n",
    "    inverse_scale) < 1e-10)\n",
    "\n",
    "undiff_prediction = invert_all_prediction_differences(\n",
    "    inverse_scale, \n",
    "    features['wind_speed'][sequence_offset+row_split:])\n",
    "\n",
    "for i, horizon in enumerate(horizons):\n",
    "    assert(mean_squared_error(\n",
    "        features['wind_speed'][sequence_offset+row_split+horizon:], \n",
    "        undiff_prediction[:-horizon,i]) < 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Build the LSTM Model\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "\n",
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "    \n",
    "#     model.add(Conv1D(layers[1], 12, input_shape=(None, layers[0])))\n",
    "\n",
    "    model.add(LSTM(\n",
    "            layers[1],\n",
    "            input_shape=(None, layers[0]),\n",
    "            return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "#     model.add(LSTM(layers[3], return_sequences=True))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(layers[5]))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(layers[4]))\n",
    "    model.add(Activation('linear'))\n",
    "    \n",
    "    model.compile(loss=\"mean_squared_error\", optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "          \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "def run_network(X_train, y_train, X_test, y_test, layers, epochs, batch_size=16):\n",
    "    model = build_model(layers)\n",
    "    history = None\n",
    "    \n",
    "    try:\n",
    "        history = model.fit(\n",
    "            X_train, y_train, \n",
    "            batch_size=batch_size, \n",
    "            epochs=epochs,\n",
    "            validation_split=0.1,\n",
    "            callbacks=[\n",
    "                TensorBoard(log_dir='./tensorboard', write_graph=True),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=15, \n",
    "                                verbose=1, mode='auto', min_lr=0.0001),\n",
    "                EarlyStopping(monitor='val_loss', patience=30, verbose=1, mode='auto'),\n",
    "                ModelCheckpoint('./model/best.hdf5', monitor='val_loss', verbose=1, \n",
    "                                save_best_only=True, mode='auto')\n",
    "            ])\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTraining interrupted\")\n",
    "    \n",
    "    predicted = model.predict(X_test, batch_size=batch_size)\n",
    "    scores = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    return model, predicted, history, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_133 (LSTM)              (None, None, 128)         70144     \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_134 (LSTM)              (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 3)                 99        \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 90,851\n",
      "Trainable params: 90,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 54645 samples, validate on 6072 samples\n",
      "Epoch 1/200\n",
      " 7968/54645 [===>..........................] - ETA: 1490s - loss: 0.8365 - acc: 0.3916\n",
      "Training interrupted\n"
     ]
    }
   ],
   "source": [
    "model, predicted, history, scores = run_network(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test,\n",
    "    y_test,\n",
    "    layers=[X_train.shape[2], 128, 30, 20, y_train.shape[1], 32],\n",
    "    epochs=200)\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# loss\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.savefig('./image/loss.png')\n",
    "plt.show()\n",
    "\n",
    "# accuracy\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "plt.plot(history.history['acc'], label='train_acc')\n",
    "plt.plot(history.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.savefig('./image/acc.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# print(\"*********************************************************\")\n",
    "# print(type(predicted)) # <class 'numpy.ndarray'>\n",
    "# print(predicted.shape) # (7594, 6)\n",
    "# print(\"*********************************************************\")\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "print(\"MAE {:.3}, RMSE {:.3f}\".format(\n",
    "    mean_absolute_error(y_test, predicted),\n",
    "    sqrt(mean_squared_error(y_test, predicted))))\n",
    "\n",
    "for i, horizon in enumerate(horizons):\n",
    "    print(\"wind speed: MAE {:.3f}, RMSE {:.3f} for horizon {}\".format(\n",
    "        mean_absolute_error(y_test[:,i], predicted[:,i]),\n",
    "        sqrt(mean_squared_error(y_test[:,i], predicted[:,i])),\n",
    "        horizon))\n",
    "\n",
    "# for i, horizon in enumerate(horizons):\n",
    "#     print(\"wind direction: MAE {:.3f}, RMSE {:.3f} for horizon {}\".format(\n",
    "#         mean_absolute_error(y_test[:,i+3], predicted[:,i+3]),\n",
    "#         sqrt(mean_squared_error(y_test[:,i+3], predicted[:,i+3])),\n",
    "#         horizon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse_scale, inverse_scale2 = invert_all_prediction_scaled(scaler, predicted, scaled.columns, horizons)\n",
    "inverse_scale = invert_all_prediction_scaled(scaler, predicted, scaled.columns, horizons)\n",
    "# print(inverse_scale.shape) # (7594, 6)\n",
    "# print(\"*********************************************************************\")\n",
    "# print(inverse_scale2.shape) # (7594, 6)\n",
    "\n",
    "predicted_signal = invert_all_prediction_differences(\n",
    "    inverse_scale, \n",
    "    features['wind_speed'][sequence_offset+row_split:])\n",
    "# print(predicted_signal.shape) # (7594, 6)\n",
    "print(predicted_signal[:5])\n",
    "# print(\"************************************************************************\")\n",
    "\n",
    "# predicted_signal2 = invert_all_prediction_differences(\n",
    "#     inverse_scale2, \n",
    "#     features['wind_direction'][sequence_offset+row_split:])\n",
    "# print(predicted_signal2[:5])\n",
    "# print(\"***************************************************************************\")\n",
    "\n",
    "for i, horizon in enumerate(horizons):\n",
    "    a = features['wind_speed'][sequence_offset+row_split+horizon:]\n",
    "    p = predicted_signal[:-horizon, i]\n",
    "    \n",
    "    print(\"Real scale wind speed: MAE {:.3f}, RMSE {:.3f} for horizon {}\".format(\n",
    "            mean_absolute_error(a, p),\n",
    "            sqrt(mean_squared_error(a, p)),\n",
    "            horizon))\n",
    "    \n",
    "# for i, horizon in enumerate(horizons):\n",
    "#     a2 = features['wind_direction'][sequence_offset+row_split+horizon:]\n",
    "#     p2 = predicted_signal2[:-horizon, i]\n",
    "\n",
    "#     print(\"Real scale wind direction: MAE {:.3f}, RMSE {:.3f} for horizon {}\".format(\n",
    "#             mean_absolute_error(a2, p2),\n",
    "#             sqrt(mean_squared_error(a2, p2)),\n",
    "#             horizon)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def SLSTM(epoch=2, batch_size=1024, layers=[35, 20]):\n",
    "    model2 = Sequential()\n",
    "    \n",
    "    model2.add(LSTM(layers[0], input_shape=(None, X_train.shape[2]), return_sequences=True))\n",
    "    model2.add(Dropout(0.2))\n",
    "    \n",
    "    model2.add(LSTM(layers[1]))\n",
    "    model2.add(Dropout(0.2))\n",
    "               \n",
    "    model2.add(Dense(y_train.shape[1]))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model2.compile(loss='mae', optimizer='rmsprop')\n",
    "    t0 = time()\n",
    "    model2.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    predicted = model2.predict(X_test, batch_size=batch_size)\n",
    "    inverse_scale = invert_all_prediction_scaled(scaler, predicted, scaled.columns, horizons)\n",
    "    predicted_signal = invert_all_prediction_differences(\n",
    "        inverse_scale, \n",
    "        features['wind_speed'][sequence_offset+row_split:])\n",
    "    for i, horizon in enumerate(horizons):\n",
    "        a = features['wind_speed'][sequence_offset+row_split+horizon:]\n",
    "        p = predicted_signal[:-horizon, i]\n",
    "        MAE = mean_absolute_error(a, p)\n",
    "        print(\"Real scale wind speed: MAE {:.3f}, RMSE {:.3f} for horizon {}\".format(\n",
    "        mean_absolute_error(a, p),\n",
    "        sqrt(mean_squared_error(a, p)),\n",
    "        horizon))\n",
    "\n",
    "    deltatime = time()-t0\n",
    "    print(\"MAE=%.5f, 消耗时间=%.4f 秒\" % (MAE, deltatime))\n",
    "\n",
    "# for batch_size in [128, 256, 512, 1024]:\n",
    "#     SLSTM(batch_size=batch_size)\n",
    "# print(\"&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\")\n",
    "for layers in [[128, 64], [64, 64], [64, 32], [32, 32]]:\n",
    "    SLSTM(layers=layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
